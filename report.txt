First of all I setup a Python interpreter that I did't have at the time on my laptop (MAC OSX)

Went to python.org and downloaded the last 2.7 version for mac, as it should be almost full compatible with the 
environment from the exercise.

For editing I used sublime text that was already installed on my MAC and for testing I used python directly from my 
command line.

I tried to stay within  docs.python.org for the most of modules and code samples.

First I read the CSV file and used the csv module. Very fast and easy to use and is a standard module.

Then I noticed I should convert the first element of each row to a timestamp (module datetime).

I decided to use a FOR loop to run trough the whole file but before I have read the first line to get the first 
timestamp. 

Inside the loop I detected the time delta of 5 seconds and calculated the average time and 99th percentile. Also, I 
stored all data inside arrays and cleaned them every 5 seconds split. This gave me more performance and very low 
memory load.

For the 99th percentile I went the easy way and used the NumPy (www.numpy.org). The tricky part was setting it up it 
in OSX. When I tested the code on my Linux boot it was as simple as 'pacman -S python-numpy' to get the module working 
from the arch linux repos. I did a short research and numpy seems to be the most complete and reliable choice.   

To be honest it took me a little bit more than one hour as I had some trouble getting the numpy running on OSX. Te 
script logic was coded somehow very quickly and easy.
